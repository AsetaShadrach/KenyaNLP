{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOa0rpv93FMa",
        "outputId": "d0e45d33-527e-4f94-9a3b-69702b11f8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y8m_APL3Jb7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCrpbarV3FMm"
      },
      "outputs": [],
      "source": [
        "path_to_json_converter = \"/content/drive/MyDrive/TwitterNLP/ref_converter.json\"\n",
        "\n",
        "with open(path_to_json_converter) as ref_json:\n",
        "    ref_dict= json.load(ref_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DarR3dTK3FMq",
        "outputId": "1663e1f9-98b2-4340-8e67-ba0082442281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9946\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/TwitterNLP/TweetsAndReplies.csv\")[:10000]\n",
        "data = data.dropna()\n",
        "print(len(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UyJ7Z50pEdCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OyUPCxQiOEb3",
        "outputId": "155cae32-601d-4ed2-855b-3fdebfda6842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet  \\\n",
              "0  Lenin died #OnThisDay 1924. He dismissed our n...   \n",
              "1  There is a â€œfundamental tension within the cli...   \n",
              "2  It is difficult to quantify exactly how much o...   \n",
              "3  Are Metaâ€™s problems a one-off or a sign of dee...   \n",
              "4  It is difficult to quantify exactly how much o...   \n",
              "\n",
              "                                               Reply  \n",
              "0   It's true. And the coverage of anything China...  \n",
              "1   What has The Economist done to protect Pacifi...  \n",
              "2       Wonder where the data for that map is from?   \n",
              "3   Burn baby burn..Facebook is on its way down.A...  \n",
              "4   Hi TheEconomists! We have the longest life ex...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c29cc20-ea8f-48f0-a7f6-97cd3fadfbc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Lenin died #OnThisDay 1924. He dismissed our n...</td>\n",
              "      <td>It's true. And the coverage of anything China...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>There is a â€œfundamental tension within the cli...</td>\n",
              "      <td>What has The Economist done to protect Pacifi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It is difficult to quantify exactly how much o...</td>\n",
              "      <td>Wonder where the data for that map is from?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are Metaâ€™s problems a one-off or a sign of dee...</td>\n",
              "      <td>Burn baby burn..Facebook is on its way down.A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It is difficult to quantify exactly how much o...</td>\n",
              "      <td>Hi TheEconomists! We have the longest life ex...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c29cc20-ea8f-48f0-a7f6-97cd3fadfbc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c29cc20-ea8f-48f0-a7f6-97cd3fadfbc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c29cc20-ea8f-48f0-a7f6-97cd3fadfbc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_emojis(text):\n",
        "    emoj = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\" \n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                      \"]+\", re.UNICODE)\n",
        "    return re.sub(emoj, '', text)"
      ],
      "metadata": {
        "id": "ZBdLZn_zEBZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_emojis(\"Hi ðŸ¤” How is your ðŸ™ˆ and ðŸ˜Œ. Have a nice weekend ðŸ’•ðŸ‘­ðŸ‘™\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4b3nMaSSEBed",
        "outputId": "08591cb8-77a1-44f7-ba25-797dfb475953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hi  How is your  and . Have a nice weekend '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.Tweet = data.Tweet.apply(remove_emojis)\n",
        "data.Reply = data.Reply.apply(remove_emojis)"
      ],
      "metadata": {
        "id": "WAzoQ4AnEBhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeMLJoxD3FMs"
      },
      "outputs": [],
      "source": [
        "def convert_to_numb(tweet_key_pair):\n",
        "    global ref_dict\n",
        "\n",
        "    #Function to update the dictionary\n",
        "    def update_ref_dict(tweet_string):\n",
        "        with open(path_to_json_converter,'r+') as file:\n",
        "            dict_data = json.load(file)\n",
        "            value = max(dict_data.values())\n",
        "\n",
        "            for item in tweet_string:\n",
        "                if item not in dict_data:\n",
        "                    value += 1\n",
        "                    dict_data[item] = value\n",
        "\n",
        "            file.seek(0)# Insert at the beginning of the file\n",
        "            ref_dict = dict_data\n",
        "            json.dump(ref_dict, file,indent=4)\n",
        "\n",
        "    # Remove leading and trailing gaps and return all character/letters\n",
        "    tweet = list(tweet_key_pair[0].strip())\n",
        "    reply = list(tweet_key_pair[1].strip())\n",
        "\n",
        "    tweet_result = list(map(ref_dict.get,tweet))\n",
        "    reply_result = list(map(ref_dict.get,reply))\n",
        "    \n",
        "    if None in tweet_result or None in reply_result:\n",
        "      update_ref_dict(tweet)\n",
        "      update_ref_dict(reply)\n",
        "      tweet_result = list(map(ref_dict.get,tweet))\n",
        "      reply_result = list(map(ref_dict.get,reply))\n",
        "    \n",
        "    tweet_result = tweet_result + [0]*(280 - len(tweet_result))\n",
        "    reply_result = reply_result + [0]*(280 - len(reply_result))\n",
        "\n",
        "     \n",
        "    if len(tweet_result)==280 and len(reply_result)==280: \n",
        "      tweet_key_pair[\"Tweet\"] = tweet_result\n",
        "      tweet_key_pair[\"Reply\"] = reply_result\n",
        "      return tweet_key_pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tt_zPy473FMv",
        "outputId": "c4979f3e-bf23-4573-d9c3-5065a1cf4620"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Tweet  \\\n",
              "0  [37, 4, 13, 8, 13, 95, 3, 8, 4, 3, 95, 54, 40,...   \n",
              "1  [34, 19, 95, 8, 18, 95, 3, 8, 5, 5, 8, 2, 20, ...   \n",
              "2  [26, 17, 4, 95, 38, 4, 19, 0, 111, 18, 95, 15,...   \n",
              "3  [34, 19, 95, 8, 18, 95, 3, 8, 5, 5, 8, 2, 20, ...   \n",
              "4  [26, 17, 4, 95, 38, 4, 19, 0, 111, 18, 95, 15,...   \n",
              "\n",
              "                                               Reply  \n",
              "0  [34, 19, 58, 18, 95, 19, 17, 20, 4, 65, 95, 26...  \n",
              "1  [48, 14, 13, 3, 4, 17, 95, 22, 7, 4, 17, 4, 95...  \n",
              "2  [27, 20, 17, 13, 95, 1, 0, 1, 24, 95, 1, 20, 1...  \n",
              "3  [33, 8, 95, 45, 7, 4, 30, 2, 14, 13, 14, 12, 8...  \n",
              "4  [50, 4, 18, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c25b1b95-690b-4220-b4ed-93dff2a98809\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[37, 4, 13, 8, 13, 95, 3, 8, 4, 3, 95, 54, 40,...</td>\n",
              "      <td>[34, 19, 58, 18, 95, 19, 17, 20, 4, 65, 95, 26...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[34, 19, 95, 8, 18, 95, 3, 8, 5, 5, 8, 2, 20, ...</td>\n",
              "      <td>[48, 14, 13, 3, 4, 17, 95, 22, 7, 4, 17, 4, 95...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[26, 17, 4, 95, 38, 4, 19, 0, 111, 18, 95, 15,...</td>\n",
              "      <td>[27, 20, 17, 13, 95, 1, 0, 1, 24, 95, 1, 20, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[34, 19, 95, 8, 18, 95, 3, 8, 5, 5, 8, 2, 20, ...</td>\n",
              "      <td>[33, 8, 95, 45, 7, 4, 30, 2, 14, 13, 14, 12, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[26, 17, 4, 95, 38, 4, 19, 0, 111, 18, 95, 15,...</td>\n",
              "      <td>[50, 4, 18, 65, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c25b1b95-690b-4220-b4ed-93dff2a98809')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c25b1b95-690b-4220-b4ed-93dff2a98809 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c25b1b95-690b-4220-b4ed-93dff2a98809');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Use copy to prevent altering the original df\n",
        "converted_tweets = data.copy().apply(convert_to_numb, axis=1).dropna().reset_index(drop=True)\n",
        "converted_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIxCbgSpNPiX"
      },
      "outputs": [],
      "source": [
        "#converted_tweets.to_csv(\"/content/drive/MyDrive/TwitterNLP/ConvertedTweets.csv\")\n",
        "#converted_tweets = pd.read_csv(\"/content/drive/MyDrive/TwitterNLP/ConvertedTweets.csv\", index_col=[0])\n",
        "#converted_tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxfCLvTOhGQM"
      },
      "outputs": [],
      "source": [
        "# To use tf.data.Dataset.from_tensor_slices, you have to pass a multidimensional array\n",
        "tweet_col = np.array([i for i in converted_tweets[\"Tweet\"]]).astype(float)\n",
        "reply_col = np.array([i for i in converted_tweets[\"Reply\"]]).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMonVF3LszzR",
        "outputId": "2fda124e-74b3-4656-acf7-ccf800b92311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9917, 280)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tweet_col.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PlxeUWANN5L",
        "outputId": "add8e1bd-fbfa-4c6f-8620-aff13974fd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37.,  4., 13., ...,  0.,  0.,  0.],\n",
              "       [34., 19., 95., ...,  0.,  0.,  0.],\n",
              "       [26., 17.,  4., ...,  0.,  0.,  0.],\n",
              "       ...,\n",
              "       [41., 14., 18., ...,  0.,  0.,  0.],\n",
              "       [36.,  4., 13., ...,  0.,  0.,  0.],\n",
              "       [41., 14., 18., ...,  0.,  0.,  0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnM8g_yB3FM3",
        "outputId": "076865fd-38d1-476c-c80a-ab2b316dac75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(280,), dtype=tf.float64, name=None), TensorSpec(shape=(280,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "#TF dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((tweet_col, reply_col))\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qnUaTNmBqy4"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(ref_dict)\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 10000\n",
        "# Number of characters in the output/tweet\n",
        "TWEET_SIZE = 280 \n",
        "EMBEDDING_DIM = 512\n",
        "RNN_UNITS = 200 #1024\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnwoX02u9wmJ"
      },
      "outputs": [],
      "source": [
        "dataset_to_use = dataset.batch(batch_size = BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6k5Pg-tb5f_",
        "outputId": "ebb8acd0-ba52-4e94-deaf-4034b2faf06d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(128, 280), dtype=tf.float64, name=None),\n",
              " TensorSpec(shape=(128, 280), dtype=tf.float64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "dataset_to_use.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Up2IpSy3FM8"
      },
      "outputs": [],
      "source": [
        "def build_model(vocab_size, rnn_units, embedding_dim, batch_size):\n",
        "  model=tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(input_dim = vocab_size, \n",
        "                                                       output_dim = embedding_dim, \n",
        "                                                       batch_input_shape=[batch_size,None]),\n",
        "                             tf.keras.layers.LSTM(units = rnn_units,\n",
        "                                                 stateful = True,\n",
        "                                                 return_sequences=True,\n",
        "                                                 dropout = 0.2),\n",
        "                             tf.keras.layers.LSTM(units = rnn_units,\n",
        "                                                 stateful = True,\n",
        "                                                 return_sequences=True,\n",
        "                                                 dropout = 0.2),\n",
        "                             tf.keras.layers.Dense(VOCAB_SIZE)\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu21XpQyoBLu",
        "outputId": "99b57b11-6af4-482c-9b14-a12173189ce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (128, None, 512)          244224    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (128, None, 200)          570400    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (128, None, 200)          320800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (128, None, 477)          95877     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,231,301\n",
            "Trainable params: 1,231,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = build_model(\n",
        "    vocab_size = VOCAB_SIZE,\n",
        "    rnn_units = RNN_UNITS, \n",
        "    embedding_dim = EMBEDDING_DIM,\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6iyXNkeqKkL",
        "outputId": "cb8fed4f-a66f-494e-a507-c4a1fbd4985c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(128, None, 477) dtype=float32 (created by layer 'dense_2')>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jh7FmWzqsGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "827d6adc-4268-487b-ea3c-8ac26127ae48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "77/77 [==============================] - 24s 261ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "20/77 [======>.......................] - ETA: 14s - loss: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-21100428aa8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                       save_weights_only = True,)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_to_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model and create checkpoints\n",
        "def model_loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=model_loss)\n",
        "\n",
        "#creat checpoint\n",
        "checkpoint_dir =\"./training_checkpoint\"\n",
        "\n",
        "# name the checpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt_{epoch}') \n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                      filepath = checkpoint_prefix,\n",
        "                      save_weights_only = True,)\n",
        "\n",
        "history = model.fit(dataset_to_use, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qu5i6wbqsKA"
      },
      "outputs": [],
      "source": [
        "model = build_model(\n",
        "    vocab_size = VOCAB_SIZE,\n",
        "    rnn_units = RNN_UNITS, \n",
        "    embedding_dim = EMBEDDING_DIM,\n",
        "    batch_size = 1\n",
        ")\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuNg0eyEVcUH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyJ9hKcZVcW8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yXUe-OEqsOP"
      },
      "outputs": [],
      "source": [
        "''' Input tweet can be None incase we want it to come \n",
        "up with a tweet or give an input tweet if we want a reply\n",
        "For now we only assume it takes in tweets and gives replies\n",
        "'''\n",
        "def generate_reply(model,input_tweet, tweet_size =TWEET_SIZE):\n",
        "  global ref_dict\n",
        "\n",
        "  # Number of characters to generate\n",
        "  input_values = list(map(ref_dict.get,input_tweet))\n",
        "  input_values = tf.expand_dims(input_values,axis=0)\n",
        "\n",
        "  # Empty list for generated result\n",
        "  idx_reply = []\n",
        "  generated_reply = []\n",
        "  ''' \n",
        "  High temp = More surprising text\n",
        "  Low temperature = More predictable text\n",
        "  '''\n",
        "  temperature =0.8\n",
        "\n",
        "  # Here batch size is 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for _ in range(tweet_size):\n",
        "    prediction = model(input_values)\n",
        "    prediction = tf.squeeze(prediction,0)\n",
        "    prediction = prediction/temperature\n",
        "\n",
        "    predicted_id = tf.random.categorical(prediction, num_samples=1)[-1,0].numpy()\n",
        "    input_values = tf.expand_dims([predicted_id],axis=0)\n",
        "\n",
        "    idx_reply.append(predicted_id)\n",
        "\n",
        "  \n",
        "  #idx_reply = predicted_ids.numpy().ravel()\n",
        "\n",
        "  for i in idx_reply:\n",
        "    generated_character = list(ref_dict.keys())[list(ref_dict.values()).index(i)]\n",
        "    if generated_character == \"null\":\n",
        "      generated_character=\"\"\n",
        "      \n",
        "    generated_reply.append(generated_character)\n",
        "    \n",
        "\n",
        "  return \"\".join(generated_reply)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7UoUH_KqsTi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b57b0517-fcdc-4a84-ffc8-dd3f09eef825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "reply = generate_reply(model,\"I think the issue may be more common than you think, ama namna gani ?\")\n",
        "reply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWIIfDVjAinq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45ec31f6-f01c-4d30-e3c2-405ac6fa0557"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoOfQSyFan8e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAiulbqmaoAh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNt9VuCQaoFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6331ddf8-3082-4de2-ab5f-9f0b7f974497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "export path = /content/drive/MyDrive/TwitterNLP/1\n",
            "\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/TwitterNLP/1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/TwitterNLP/1/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9cf7e37a90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f9cf845da90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved model:\n",
            "total 1436\n",
            "drwx------ 2 root root    4096 Mar  4 17:22 assets\n",
            "-rw------- 1 root root   13822 Mar 20 12:06 keras_metadata.pb\n",
            "-rw------- 1 root root 1448238 Mar 20 12:06 saved_model.pb\n",
            "drwx------ 2 root root    4096 Mar 20 12:06 variables\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = \"/content/drive/MyDrive/TwitterNLP\"\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite = True,\n",
        "    include_optimizer = True,\n",
        "    save_format = None,\n",
        "    signatures = None,\n",
        "    options = None\n",
        ")\n",
        "print(\"\\nSaved model:\")\n",
        "!ls -l {export_path}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia7fuAlNaq6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de4b54c-d809-4d1b-f849-6a99813509c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['embedding_1_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (1, -1)\n",
            "        name: serving_default_embedding_1_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (1, -1, 2223)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Concrete Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_1_input: TensorSpec(shape=(1, None), dtype=tf.float32, name='embedding_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(1, None), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_1_input: TensorSpec(shape=(1, None), dtype=tf.float32, name='embedding_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(1, None), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_1_input: TensorSpec(shape=(1, None), dtype=tf.float32, name='embedding_1_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_1_input: TensorSpec(shape=(1, None), dtype=tf.float32, name='embedding_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          embedding_1_input: TensorSpec(shape=(1, None), dtype=tf.float32, name='embedding_1_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(1, None), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(1, None), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC9QWwAgarFp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model(export_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQr5UHvvEhWp",
        "outputId": "5f07c763-b38c-43ee-b655-8418b97b6d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check its architecture\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUprAKvXEhaE",
        "outputId": "3cb1ed44-54d2-42f9-dc13-70635235c5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (1, None, 512)            1138176   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (1, None, 200)            570400    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (1, None, 200)            320800    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 2223)           446823    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,476,199\n",
            "Trainable params: 2,476,199\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reply = generate_reply(new_model, \"Ona sasa\")\n",
        "print(len(reply),\"\\n\",reply)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlYYPfNTEhd1",
        "outputId": "c00d934f-b719-43c8-840b-1e3a3d71e784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 \n",
            "  o â€™tfa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_juZZ6kGEg5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}